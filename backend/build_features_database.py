import pickle
import json
import numpy as np
from pathlib import Path
from tqdm import tqdm
import os

from config import Config
from models.feature_extractor import FeatureExtractor
# Mise Ã  jour de l'importation pour Ã©viter les boucles
from utils.similarity_search import SimilaritySearch

def build_feature_database():
    """
    Construire la base de features pour TOUS les produits
    Utilise automatiquement les images prÃ©traitÃ©es si disponibles
    """
    print("=" * 70)
    print("ğŸš€ CONSTRUCTION DE LA BASE DE FEATURES")
    print("=" * 70)
    
    # 1. VÃ©rifier si les images prÃ©traitÃ©es existent
    preprocessed_metadata_file = os.path.join(Config.DATA_DIR, 'metadata_preprocessed.json')
    
    print("\nğŸ“‚ Chargement des mÃ©tadonnÃ©es...")
    
    if os.path.exists(preprocessed_metadata_file):
        # Utiliser les images PRÃ‰TRAITÃ‰ES
        print("   ğŸ” Images prÃ©traitÃ©es dÃ©tectÃ©es !")
        with open(preprocessed_metadata_file, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        print("   âœ… Utilisation des images PRÃ‰TRAITÃ‰ES")
        print(f"      Dossier : data/preprocessed/")
    else:
        # Utiliser les images ORIGINALES
        print("   âš ï¸  Aucune image prÃ©traitÃ©e trouvÃ©e")
        print("   ğŸ’¡ ExÃ©cutez d'abord : python preprocess_dataset.py")
        with open(Config.METADATA_FILE, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        print("   â„¹ï¸  Utilisation des images ORIGINALES")
        print(f"      Dossier : data/products/")
    
    print(f"\n   ğŸ“Š {metadata['total_products']} produits Ã  traiter")
    
    # 2. Initialiser l'extracteur de features
    print("\nğŸ¤– Initialisation du modÃ¨le ResNet50...")
    extractor = FeatureExtractor(Config.MODEL_NAME)
    
    # 3. Extraire les features de toutes les images
    print("\nâš™ï¸  Extraction des features en cours...")
    print("   (Cela peut prendre 5-15 minutes selon votre machine)\n")
    
    features_dict = {}  # {image_path: features}
    features_list = []
    image_paths = []
    valid_products = []
    
    # Barre de progression
    for product in tqdm(metadata['products'], desc="Extraction", unit="image"):
        img_path = product['image_path']
        
        # VÃ©rifier que l'image existe
        if not os.path.exists(img_path):
            print(f"\nâš ï¸  Image non trouvÃ©e : {img_path}")
            continue
        
        # Extraire les features
        features = extractor.extract_features(img_path)
        
        if features is not None:
            features_dict[img_path] = features
            features_list.append(features)
            image_paths.append(img_path)
            valid_products.append(product)
        else:
            print(f"\nâŒ Ã‰chec extraction : {img_path}")
    
    # 4. Convertir en matrice numpy
    print(f"\n\nğŸ“Š Conversion en matrice numpy...")
    features_matrix = np.array(features_list).astype('float32')
    
    print(f"   âœ… Matrice crÃ©Ã©e : {features_matrix.shape}")
    print(f"      â€¢ Nombre d'images : {features_matrix.shape[0]}")
    print(f"      â€¢ Dimension des features : {features_matrix.shape[1]}")
    
    # 5. CrÃ©er le dossier features s'il n'existe pas
    os.makedirs(Config.FEATURES_DIR, exist_ok=True)
    
    # 6. Sauvegarder les donnÃ©es
    print(f"\nğŸ’¾ Sauvegarde des donnÃ©es...")
    
    # Sauvegarder le dictionnaire
    with open(Config.FEATURES_DB_FILE, 'wb') as f:
        pickle.dump(features_dict, f)
    print(f"   âœ… Dictionnaire sauvegardÃ© : {Config.FEATURES_DB_FILE}")
    
    # Sauvegarder la matrice
    np.save(Config.FEATURES_MATRIX_FILE, features_matrix)
    print(f"   âœ… Matrice sauvegardÃ©e : {Config.FEATURES_MATRIX_FILE}")
    
    # Sauvegarder les chemins d'images
    with open(Config.IMAGE_PATHS_FILE, 'wb') as f:
        pickle.dump(image_paths, f)
    print(f"   âœ… Chemins sauvegardÃ©s : {Config.IMAGE_PATHS_FILE}")
    
    # Sauvegarder les produits valides
    valid_metadata = {
        'products': valid_products,
        'categories': metadata['categories'],
        'total_products': len(valid_products)
    }
    
    valid_metadata_file = Config.METADATA_FILE.replace('.json', '_valid.json')
    with open(valid_metadata_file, 'w', encoding='utf-8') as f:
        json.dump(valid_metadata, f, indent=4, ensure_ascii=False)
    print(f"   âœ… MÃ©tadonnÃ©es valides : {valid_metadata_file}")
    
    # 7. Initialiser le systÃ¨me de recherche
    print(f"\nğŸ”¨ Initialisation du systÃ¨me de recherche...")
    print(f"   MÃ©trique : Cosine Similarity")
    
    search_engine = SimilaritySearch(
        features_matrix=features_matrix,
        image_paths=image_paths,
        metric='cosine'
    )
    
    # Sauvegarder l'objet de recherche
    search_data_file = os.path.join(Config.FEATURES_DIR, 'search_engine.pkl')
    search_engine.save_data(search_data_file)
    
    # 8. RÃ©capitulatif
    print("\n" + "=" * 70)
    print("âœ… BASE DE FEATURES CRÃ‰Ã‰E AVEC SUCCÃˆS !")
    print("=" * 70)
    print(f"ğŸ“Š Statistiques finales :")
    print(f"   â€¢ Images traitÃ©es : {len(features_list)} / {metadata['total_products']}")
    print(f"   â€¢ Images prÃ©traitÃ©es : {'Oui' if os.path.exists(preprocessed_metadata_file) else 'Non'}")
    print(f"   â€¢ Dimension des features : {features_matrix.shape[1]}")
    print(f"   â€¢ Taille totale : {features_matrix.nbytes / (1024*1024):.2f} MB")
    print(f"   â€¢ MÃ©trique de similaritÃ© : Cosine Similarity & Euclidean Distance")
    print(f"\nğŸ“ Fichiers crÃ©Ã©s dans : {Config.FEATURES_DIR}")
    print(f"   â€¢ features_db.pkl")
    print(f"   â€¢ features_matrix.npy")
    print(f"   â€¢ image_paths.pkl")
    print(f"   â€¢ search_engine.pkl")
    print("=" * 70 + "\n")
    
    return features_matrix, image_paths

if __name__ == '__main__':
    build_feature_database()