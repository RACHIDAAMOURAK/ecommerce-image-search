import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.preprocessing import image
import numpy as np
import os
from config import Config

class FeatureExtractor:
    """
    Extracteur de features utilisant ResNet50 prÃ©-entraÃ®nÃ© sur ImageNet
    """
    
    def __init__(self, model_name='ResNet50'):
        """
        Initialiser le modÃ¨le prÃ©-entraÃ®nÃ©
        
        Args:
            model_name (str): Nom du modÃ¨le Ã  utiliser
        """
        print(f"ğŸ”„ Chargement du modÃ¨le {model_name}...")
        
        # Charger ResNet50 sans la couche de classification (include_top=False)
        # pooling='avg' pour obtenir un vecteur de features de taille fixe
        self.model = ResNet50(
            weights='imagenet',      # Poids prÃ©-entraÃ®nÃ©s
            include_top=False,       # Sans couche de classification
            pooling='avg',           # Global Average Pooling
            input_shape=(224, 224, 3)
        )
        
        # Le modÃ¨le ne sera pas entraÃ®nÃ©
        self.model.trainable = False
        
        print(f"âœ… ModÃ¨le {model_name} chargÃ© avec succÃ¨s!")
        print(f"   ğŸ“Š Dimension du vecteur de features : {self.model.output_shape[1]}")
    
    def extract_features(self, img_path):
        """
        Extraire les features d'une seule image
        
        Args:
            img_path (str): Chemin vers l'image
            
        Returns:
            numpy.ndarray: Vecteur de features normalisÃ© (2048 dimensions)
        """
        try:
            # 1. Charger l'image et la redimensionner
            img = image.load_img(img_path, target_size=Config.IMAGE_SIZE)
            
            # 2. Convertir en array numpy
            img_array = image.img_to_array(img)
            
            # 3. Ajouter une dimension batch (le modÃ¨le attend (batch, height, width, channels))
            img_array = np.expand_dims(img_array, axis=0)
            
            # 4. PrÃ©traiter selon ResNet50 (normalisation spÃ©cifique)
            img_array = preprocess_input(img_array)
            
            # 5. Extraire les features
            features = self.model.predict(img_array, verbose=0)
            
            # 6. Aplatir le vecteur (de (1, 2048) vers (2048,))
            features = features.flatten()
            
            # 7. Normaliser le vecteur (norme L2)
            # Cela permet de comparer les similaritÃ©s avec le cosine similarity
            norm = np.linalg.norm(features)
            if norm != 0:
                features = features / norm
            
            return features
            
        except Exception as e:
            print(f"âŒ Erreur lors de l'extraction de {img_path}: {e}")
            return None
    
    def extract_features_batch(self, img_paths, batch_size=32):
        """
        Extraire les features pour un lot d'images (plus rapide)
        
        Args:
            img_paths (list): Liste des chemins d'images
            batch_size (int): Taille du lot
            
        Returns:
            numpy.ndarray: Matrice de features (n_images, 2048)
        """
        all_features = []
        
        for i in range(0, len(img_paths), batch_size):
            batch_paths = img_paths[i:i+batch_size]
            batch_images = []
            
            # Charger et prÃ©traiter le lot d'images
            for img_path in batch_paths:
                try:
                    img = image.load_img(img_path, target_size=Config.IMAGE_SIZE)
                    img_array = image.img_to_array(img)
                    batch_images.append(img_array)
                except Exception as e:
                    print(f"âš ï¸  Erreur sur {img_path}: {e}")
                    continue
            
            if len(batch_images) > 0:
                # Convertir en array et prÃ©traiter
                batch_array = np.array(batch_images)
                batch_array = preprocess_input(batch_array)
                
                # Extraire les features
                features = self.model.predict(batch_array, verbose=0)
                
                # Normaliser
                for j in range(len(features)):
                    feature = features[j].flatten()
                    norm = np.linalg.norm(feature)
                    if norm != 0:
                        feature = feature / norm
                    all_features.append(feature)
        
        return np.array(all_features)

# Test du module
if __name__ == '__main__':
    print("ğŸ§ª Test du Feature Extractor\n")
    
    # Initialiser l'extracteur
    extractor = FeatureExtractor()
    
    # Tester sur une image
    test_image = 'data/products/bag/bag1.png'
    
    if os.path.exists(test_image):
        print(f"\nğŸ“· Test sur : {test_image}")
        features = extractor.extract_features(test_image)
        
        if features is not None:
            print(f"âœ… Features extraites avec succÃ¨s !")
            print(f"   ğŸ“Š Shape : {features.shape}")
            print(f"   ğŸ“ Norme : {np.linalg.norm(features):.6f}")
            print(f"   ğŸ“ˆ Min : {features.min():.6f}, Max : {features.max():.6f}")
    else:
        print(f"âŒ Image de test non trouvÃ©e : {test_image}")
        print("âš ï¸  Assurez-vous d'avoir copiÃ© votre dataset dans data/products/")